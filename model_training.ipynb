{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load datasets from csv files\n",
    "Dataframes 1 and 2 are loaded from dataset1 and dataset2 csv files respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset1.csv')\n",
    "df2 = pd.read_csv('dataset2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation\n",
    "### 3.1. Data preprocessing\n",
    "Since algorithms can only process numeric datas, we need to convert the scraped data previously to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#to begin, transform job name and company name to lower case\n",
    "df1['name'].str.lower()\n",
    "df1['company'].str.lower()\n",
    "df2['name'].str.lower()\n",
    "df2['company'].str.lower()\n",
    "\n",
    "#remove everything in names' strings except for the words and numbers\n",
    "df1['name'].replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "df1['company'].replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "df2['name'].replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "df2['company'].replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "\n",
    "#convert a collection of raw documents to a matrix of TF-IDF features with TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X1_tfdif = vectorizer.fit_transform(df1['name'])\n",
    "X2_tfdif = vectorizer.fit_transform(df2['name'])\n",
    "\n",
    "#use DictVectorizer to do binary one-hot (aka one-of-K) coding\n",
    "#it means one boolean-valued feature is constructed for each of the possible string values that the feature can take on.\n",
    "encoder = DictVectorizer()\n",
    "X1_categ = encoder.fit_transform(df1[['company','location']].to_dict('records'))\n",
    "X2_categ = encoder.fit_transform(df2[['company','location']].to_dict('records'))\n",
    "\n",
    "#stack together to get the input matrix to fit in models\n",
    "X1 = hstack([X1_tfdif, X1_categ])\n",
    "X2 = hstack([X2_tfdif, X2_categ])\n",
    "\n",
    "#output value\n",
    "y1 = df1['average_salary']\n",
    "y2 = df2['average_salary']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Split the preprocessed data above to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 475) (40, 475) (160,) (40,) (195, 422) (49, 422) (195,) (49,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split X1, y1, X2, and y2 to training and testing sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2)\n",
    "\n",
    "#shapes of sets\n",
    "print(X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape, X2_train.shape, X2_test.shape, y2_train.shape, y2_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train models\n",
    "### 4.1. Train Decision Tree model with dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Decision Tree on dataset1: 9.357483636106451\n",
      "MAPE of Decision Tree on dataset1: 0.2604386463786489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "import pickle\n",
    "\n",
    "#fit DecisionTreeRegressor on dataset1\n",
    "decision_dataset1 = DecisionTreeRegressor(random_state=0)\n",
    "decision_dataset1.fit(X1_train, y1_train)\n",
    "y1_pred = decision_dataset1.predict(X1_test)\n",
    "\n",
    "#save model to pickle file\n",
    "pickle.dump(decision_dataset1, open('decision_dataset1.pkl','wb'))\n",
    "\n",
    "#calculate mean squared error, squared = False to return RMSE\n",
    "print('RMSE of Decision Tree on dataset1: ' + str(mean_squared_error(y1_test, y1_pred, squared=False)))\n",
    "\n",
    "#calculate MAPE\n",
    "print('MAPE of Decision Tree on dataset1: ' + str(mean_absolute_percentage_error(y1_test, y1_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Train Decision Tree model with dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Decision Tree on dataset2: 19.312946012583087\n",
      "MAPE of Decision Tree on dataset2: 512.2479966950489\n"
     ]
    }
   ],
   "source": [
    "#fit DecisionTreeRegressor on dataset2\n",
    "decision_dataset2 = DecisionTreeRegressor(random_state=0)\n",
    "decision_dataset2.fit(X2_train, y2_train)\n",
    "y2_pred = decision_dataset2.predict(X2_test)\n",
    "\n",
    "#save model to pickle file\n",
    "pickle.dump(decision_dataset2, open('decision_dataset2.pkl','wb'))\n",
    "\n",
    "#calculate mean squared error, squared = False to return RMSE\n",
    "print('RMSE of Decision Tree on dataset2: ' + str(mean_squared_error(y2_test, y2_pred, squared=False)))\n",
    "\n",
    "#calculate MAPE\n",
    "print('MAPE of Decision Tree on dataset2: ' + str(mean_absolute_percentage_error(y2_test, y2_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Train Random Forest model with dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Random Forest on dataset1: 9.361470971487334\n",
      "MAPE of Random Forest on dataset1: 0.30490737273499996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#fit RandomForestRegressor to dataset1\n",
    "forest_dataset1 = RandomForestRegressor(random_state=0)\n",
    "forest_dataset1.fit(X1_train, y1_train)\n",
    "y1_pred = forest_dataset1.predict(X1_test)\n",
    "\n",
    "#save model to pickle file\n",
    "pickle.dump(forest_dataset1, open('forest_dataset1.pkl','wb'))\n",
    "\n",
    "#calculate mean squared error, squared = False to return RMSE\n",
    "print('RMSE of Random Forest on dataset1: ' + str(mean_squared_error(y1_test, y1_pred, squared=False)))\n",
    "\n",
    "#calculate MAPE\n",
    "print('MAPE of Random Forest on dataset1: ' + str(mean_absolute_percentage_error(y1_test, y1_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Train Random Forest model with dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Random Forest on dataset2: 13.542348538901884\n",
      "MAPE of Random Forest on dataset2: 476.39601535370184\n"
     ]
    }
   ],
   "source": [
    "#fit RandomForestRegressor to dataset2\n",
    "forest_dataset2 = RandomForestRegressor(random_state=0)\n",
    "forest_dataset2.fit(X2_train, y2_train)\n",
    "y2_pred = forest_dataset2.predict(X2_test)\n",
    "\n",
    "#save model to pickle file\n",
    "pickle.dump(forest_dataset2, open('forest_dataset2.pkl','wb'))\n",
    "\n",
    "#calculate mean squared error, squared = False to return RMSE\n",
    "print('RMSE of Random Forest on dataset2: ' + str(mean_squared_error(y2_test, y2_pred, squared=False)))\n",
    "\n",
    "#calculate MAPE\n",
    "print('MAPE of Random Forest on dataset2: ' + str(mean_absolute_percentage_error(y2_test, y2_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "624c38d1f4430c44386106613011096f1c69ad2b787f87487785fd06f2d69825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
